%--------------------------------------
% Master's Thesis Title Page
% LaTeX Template
% Version 1.0 (23/05/14)
%---------------------------------------

%----------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass[a4paper]{report}
\usepackage{helvet}
\usepackage[toc,acronym,nomain]{glossaries}
\usepackage{graphicx} % Displaying pictures in the document.
\usepackage[floatrow]{chemstyle} % Displaying figures next to item lists.
\usepackage[hidelinks]{hyperref}
\usepackage{listings} % Adding source code listings.
\usepackage{caption}
\usepackage{algpseudocode}
\usepackage{subcaption}
\usepackage{color}
\usepackage[usenames,dvipsnames]{xcolor}
\usepackage{epstopdf}
\usepackage{gensymb}
\usepackage{mathtools}
\usepackage{courier}

\include{glossary}
\makeglossaries
\definecolor{mygreen}{rgb}{0,0.8,0}
\definecolor{mygray}{rgb}{0.5,0.5,0.5}
\definecolor{listinggray}{gray}{0.5}
\definecolor{lbcolor}{rgb}{0.95,0.95,0.95}

\newcommand{\codeword}[1]{\texttt{#1}}

% Solarized colour scheme for listings
\definecolor{variable}{RGB}{43, 145, 175}
\definecolor{keyword}{RGB}{0, 0, 255}
\definecolor{number}{HTML}{0080A0}
\definecolor{string}{RGB}{163, 21, 21}
\definecolor{comment}{RGB}{0, 128, 0}
\definecolor{background}{HTML}{FFFFFF}
\definecolor{function}{RGB}{111, 0, 138}

% Define C++ syntax highlighting colour scheme
\lstset{language=C++,
		backgroundcolor=\color{background},
        basicstyle=\small\ttfamily,
        numbers=left,
        tabsize=2,
        breaklines=true,
        escapeinside={@}{@},
        numberstyle=\tiny\color{black},
        keywordstyle=\color{keyword},
        stringstyle=\color{string}\ttfamily,
        %identifierstyle=\color{function},
        commentstyle=\color{comment},
       %directivestyle=\color{black},
        frame=single,
        rulecolor=\color{black},
        showstringspaces=false,
        captionpos=b
}
\DeclareCaptionFont{code}{\color{black}}
\DeclareCaptionFormat{listing}{ #1#2#3  }
\captionsetup[lstlisting]{ format=listing, labelfont=code, textfont=code, singlelinecheck=false, margin=0pt, font={bf,footnotesize} }

\lstnewenvironment{code}[1][]%
{
   \noindent
   \minipage{\linewidth}
   \vspace{0.5\baselineskip}
   \lstset{basicstyle=\ttfamily\footnotesize,frame=single,#1}}
{\endminipage}
%----------------------------------------------------------------------------------------
%	TITLE PAGE
%----------------------------------------------------------------------------------------

\newcommand*{\titlePage}{\begingroup % Create the command for including the title page in the document
\fontfamily{phv}\selectfont
\centering % Center all text

\vspace{200pt}
{\Huge Simulating TPC Readout Electronics} \\ % Title
\vspace{5pt}

{\Large \textsl{Consectetur adipisicing elit, sed do tempor incididunt ut labore et dolore magna aliqua}} % Subtitle or further description
\vspace{50pt}

{\Large{H\r{a}vard Rustad Olsen}}\\ % Author name

\vfill % Whitespace between the author name and the publisher logo

{\Large Master's thesis in Software Engineering at \\
\vspace{10pt}
Department of Computing, Mathematics and Physics, \\
Bergen University College \\
\vspace{10pt}
Department of  Informatics, \\
University of Bergen \\}
\vspace{10pt}
{\large June 2015} % Month and year published


\begin{figure}[h]
		\begin{subfigure}[]{50pt}
			\includegraphics[width=50pt]{HIB_sort_hovedlogo.eps}
		\end{subfigure}
		\hfill
		\begin{subfigure}[]{50pt}
			\includegraphics[width=50pt]{uib-logo.eps}
		\end{subfigure}

\end{figure}

\endgroup}

%----------------------------------------------------------------------------------------
%	BLANK DOCUMENT
%----------------------------------------------------------------------------------------

\begin{document}

\pagestyle{plain} % Removes page numbers

\titlePage % This command includes the title page

\newpage

\chapter*{Acknowledgements}
\addcontentsline{toc}{chapter}{Acknowledgments}

\paragraph{•}
Håvard Helstrup, Johan Alme, Dieter, Arild, Christian, (Damian).
\newpage

\phantomsection
\addcontentsline{toc}{chapter}{Contents}
\tableofcontents

\newpage
\phantomsection
\addcontentsline{toc}{chapter}{List of Figures}
\listoffigures

\newpage
\phantomsection
\addcontentsline{toc}{chapter}{List of Tables}
\listoftables

\newpage
\chapter*{List of Algorithms}
\addcontentsline{toc}{chapter}{List of Algorithms}

\newpage
\phantomsection
\addcontentsline{toc}{chapter}{Listings}
\lstlistoflistings
\newpage

% Glossary
%\chapter*{Glossary and acronyms}
%\addcontentsline{toc}{chapter}{Glossary and acronyms}
\printglossaries
\newpage

\chapter{Introduction}
\textit{This chapter will cover the motivation, as well as the scope and goal of this report.}

\section{Motivation}
\label{sec:motivation}
\paragraph{•}
The \gls{lhc} at the \gls{cern} is the world's largest particle accelerator, hosting multiple ongoing experiments.
After a run period of more than 3 years, the \gls{lhc} at the \gls{cern} will be shut down from 2018 until 2021.\cite{ls2}
The purpose of this shutdown is to do maintenance on various equipment in the \gls{lhc}, as well as significant upgrades to the different detectors, one of which is the detector for the \gls{alice}.
\gls{alice} consists of multiple sub-detectors, which combined collect an enormous amount of data.
This amount is expected to increase after the shutdown period as the interaction rate of the \gls{lhc} will increase.
Due to the increase in data output, the \gls{alice} collaboration is seeking to upgrade and enhance the detector capabilities.\cite{alice-upgrade}
This includes a partial redesign of the readout electronics, upgrades to multiple sub-detectors and additional hardware upgrades.

\paragraph{•}
The \gls{tpc} is the \gls{alice} detector's main sub-detector for tracking and identifying particles.
A starting/temporary? design for the new \gls{tpc} readout electronics is made, and the different components are currently being developed.
As this is still being worked on, many questions about the different components are yet to be answered.
Are the current specifications sufficient to handle the expected increase in output from the detector?
Do they have the necessary bandwidth to be able to send the data with minimal sample loss.
Are the buffer memory enough to handle the traffic.
Is it possible to optimize the current solution in any way?

\paragraph{•}
The previous paragraph motivates us to find a reliable way of determining a sufficient design for the readout electronics, while being both time and cost efficient.
One strategy for solving this problem, which will be further explored in this thesis is creating a simulation of the system.
Doing a simulation requires designing a accurate representation of the readout electronics, and creating a testbench where it is possible to configure and run multiple tests.


\section{Research Question and thesis goal}

\paragraph{•}
Given the motivation and introduction given in section \ref{sec:motivation} the research question for this thesis becomes:

\paragraph{•}
Is it possible to design and implement a simulation which directly represent the readout electronics, and in doing so will it have an optimizing effect?

\paragraph{•}
Further explained, the main tasks of this thesis will be to create a computer model of the readout electronics main components, and run multiple simulations on it.
Experimenting with different configurations in order to find bottlenecks, faulty design or areas of improvement.
The experiments should be logged, and the results will be presented in an organized fashion.


\section{Report structure}
Chapter 2 will give the reader the background information to be able to understand the different academic and scientific terms used, as well as some information about the context of the report.
This includes information about \gls{cern}, the \gls{alice} experiment and the physics most relevant to the thesis.
It will discuss the current readout electronics as well as the proposed upgrade.
Chapter 3 is going further into the problem discussed in this report, initial plans on solving the problem, and information about the tools used.
Chapter 4 will talk about the implementation of the simulation, what problems occurred along the way, and the chosen solution.
The chapter will go into the design, as well as code snippets from the implementation.
With the information given in chapter 4, chapter 5 will discuss the results of the different simulations run, and evaluate the solution.
Chapter 6 will conclude the thesis with some closing words, and work that can be done in the future.


\chapter{Background}
\textit{This chapter will give the reader the background needed to set the rest of the thesis in context.}

\section{CERN}
\paragraph{•}
\gls{cern} is a European research and scientific organization based out of Geneva near the Franco-Swiss border.\cite{cern}
\gls{cern} is a collaboration between 21 countries with a member staff of over 2500, and more than 12000 associates and apprentices.
The organization was founded in 1954 and has since then been the birthplace of many major scientific discoveries.
These are not limited to discoveries in the field of physics, but includes the creation of the World Wide Web.\cite{www}
Currently the biggest project at \gls{cern} is the \gls{lhc} particle accelerator, which serves as the foundation for multiple experiments in the field of particle physics.
% 2 - 3 more sentences about this!

\section{The Large Hadron Collider}
\label{sec:lhc}
\paragraph{•}
Starting up on 10 September 2008, \gls{lhc} is the latest construct added to \gls{cern}'s particle accelerator complex.\cite{lhc}
It consist of a 27 kilometre underground ring of superconducting magnets and accelerators which boost the energy of the particles travelling inside the collider.
The collider contains two adjacent parallel high-energy particle beams.
These beams consist of protons extracted from standard hydrogen atoms by stripping them of electrons.
Along the collider ring there are four intersect points where collision occurs.
Each point corresponds to the location of a particle detector - ATLAS, \gls{alice}, CMS and LHCb.
The particle detectors are each built and operated by a large collaborations, with thousands of scientists from different institutes around the world.
The beams travel at close to the speed of light and are guided by a magnetic field, which is created and maintained by superconducting electromagnets.
Superconducting meaning that its in a state where it can most efficiently conduct electricity, without resistance or energy loss.
Achieving this state requires cooling the magnets to -271.3\degree~C , which is done by the distribution of liquid helium.
The layout of the \gls{lhc} ring as well as its four collision points can be seen in \ref{fig:lhc}.

\begin{figure}[h!]
  \centering
    \includegraphics[width=0.7\textwidth]{images/lhc-ring.jpg}
     \caption{The Large Hadron Collider}
    \label{fig:lhc}
\end{figure}

\paragraph{•}
The beams travelling inside the \gls{lhc} reach an energy-peak of 7 \gls{tev}, which means that on impact with each other the collision reach an energy of 14 \gls{tev}.\cite{lhc-pdf}
During a normal run of the collider there will be about 600 million particle collisions per second during a period of 10 hours.
This leads to a huge amount of data for each of the detectors to read out.
\gls{alice} is the detector which produce the most data per collision, with a design value of about 1.25 GB/s.
The high amount of data per collision is produced primarily by the \gls{tpc} sub-detector, which records a high number of points per track, and has a low momentum threshold. Detectors like ATLAS and CMS  are designed with a higher momentum threshold, but can cope with significantly higher collision rates than ALICE. ALICE is designed for the study of heavy ion reactions, where particle correlations at low momentum is an important measure.

\section{ALICE}
\subsection{Introduction}

\paragraph{•}
\gls{alice} is a so called heavy-ion detector, which means it studies collisions between heavy nuclei of high energy.\cite{alice-home}
When the experiment started heavy-ion collision lead ions was used, but they have now switched to colliding lead with protons, both produce a extreme high amount of temperature and density.
They will eventually run collisions with lead to lead ions again as both types create interesting results.
Lead to lead collisions create Hot Nuclear Matter, while lead to protons create Cold Nuclear Matter.
The explanations for these types of matter is beyond the scope of this thesis and will not be discussed further.
The high temperature and density is necessary to produce a phase of matter called quark-gluon plasma.

\subsection{Quark-gluon plasma}
\paragraph{•}
Shortly after the big bang, the universe was filled with a extremely hot cluster of all kinds of different particles moving around at near light speed.\cite{alice-physics}
Most of these particles were quarks, fundamental building blocks for matter, and gluons which ties quarks together in order to form heavier particles.
Normally quarks and gluons are very strictly tied together, but in the conditions of extreme temperature and density as in the time shortly after the big bang, that they are allowed to move freely in an extended volume called quark-gluon plasma.
The existence of quark-gluon plasma and its properties is one of the key issues in \gls{qcd}.
The \gls{alice} collaboration studies this, observing how it behaves.

\subsection{The detector setup}
\paragraph{•}
The detector weight is about 10,000 ton, it is 26 m long, 16 m wide, and 16 m high.\cite{alice-about}
It consists of 18 sub-detectors, each with its own set of tasks regarding tracking particles and collecting data.
This large number of sub-detectors are needed in order to get the full picture of the complex system which is being studied(i.e different types of particles and the correlations between them).
Most of the detector is embedded in a magnetic field, created by a large solenoid magnet, which makes particles formed in collision bend according to their charge, and behave differently relative to their momentum. High momentum equals near straight lines while low momentum makes the particles move in spiral-like tracks.
During lead to lead collisions the collision rate peaks at 8 kHz(Where Hz is defined as number of events per second).
This number is still a lot lower in practice because the \gls{alice} detector uses a triggered readout, which only triggers on head-on(central) collisions.
The maximum readout rate of the current \gls{alice} detector is 500 Hz, which is more than enough to track central collisions.
\ref{fig:alice} shows a cross section of the detector as it is today with the red solenoid magnet, and all sub-detectors labeled.

\begin{figure}[h!]
  \centering
    \includegraphics[width=1.0\textwidth]{images/alice-detector.png}
     \caption{The ALICE detector}
    \label{fig:alice}
\end{figure}

\section{The TPC detector}
\subsection{Intro}
\paragraph{•}
One of the most important sub-detectors, and the one that is relevant for this thesis is the \gls{tpc} detector.
Located at the center of the \gls{alice} detector it is among the first entry point when gathering data from a particle collision.
It is a 88\(m^3\) cylinder filled with gas.
The gas works as a detection medium, which means that charges particles from a collision crossing will ionize the gas atoms, freeing electrons that move towards the end plates of the detector.
The readout is done by specially designed readout chambers, which are capable of handling the high amount of data produced in heavy-ion collisions.

\subsection{Readout electronics} %Should this be a chapter of itself?
\paragraph{•}
Signals from the readout chambers are passed along to the front-end readout electronics, which today consist of 4356 \gls{altro} \gls{asic} chips.\cite{altro}
\gls{asic} is the term used for specially customized chips, rather than chips with a more general-purpose use.\cite{asic}
The \gls{altro} chip is made up of 16 asynchronous channels that digitize, process and compress the analogue signals from the readout chambers.
It operates on a so called triggered readout mode.
In short when \gls{altro} receives the first trigger, it stores the following data stream into memory, holding on to it until it is ready to pass on the data.
The front-end electronics are able to readout data at a speed of up to 300 MB/s.
\paragraph{•}
The \gls{altro} chip sends the digitized signals further down the readout chain to the \gls{rcu}, where it is further processed and shipped to  and stored in the online systems.
The schematics is shown in \ref{fig:altro}.

\begin{figure}[h!]
  \centering
    \includegraphics[width=0.75\textwidth]{images/altro.png}
     \caption{Readout schematics for the current TPC detector}
    \label{fig:altro}
\end{figure}

\section{Long Shutdown 2}
\paragraph{•}
As mentioned in \ref{sec:motivation} the \gls{lhc} ring will be shut down for about 3 years, starting 2018.
During that time the \gls{alice} detector will undergo an extensive upgrade.
The upgrade strategy for \gls{alice} is based on the expected increase in collision rate to 50 kHz, and will now track every collision.
Essentially this comes down to a increase by a factor of 100, compared to what is achievable today.

\paragraph{•} %NEW SHIT
{\color{red} To be able to handle the increase in collision rate the \gls{tpc} will receive upgrades to both its readout chambers, and front-end readout electronics.
The current \gls{mwpc} based read-out chambers will be switched out for \gls{gem} detectors, which has a much higher readout rate capability.
Signals will be passed from the new readout chambers to the \gls{fec} via a readout pad structure similar to the one presently used.
There are multiple pad structure depending on its location on the detector, but the difference in structure is not relevant for this thesis.
What is relevant however is that more data is expected from low pad numbers, an example of a pad structure is shown in figure~\ref{fig:pad-struct}.

\begin{figure}[h!]
	\centering
		\includegraphics[width=0.75\textwidth]{images/pad-structure.png}
		\caption{Pad structure of an Inner Readout Chamber(IROC) (Credit to Christian Lippmann)}
		\label{fig:pad-struct}
\end{figure}

\paragraph{}
The entry point in the \gls{fec} is the new custom-made \gls{asic}, the \gls{sampa}, which is replacing the \gls{altro} chip.\cite{tdr-015}
The \gls{sampa} chip is capable of processing signals asynchronously in 32 individual channels, each channel is directly connected to a single pad.
They are further on digitized and concurrently transferred to the \gls{gbt}, which enhances the signal strength and transmits them via multiple optical fiber links to the \gls{cru}.
The \gls{cru} can be thought of as the new \gls{rcu} and serves as an interface to the online systems.
The data flow from the detector, and a working schematics can be seen in figure~\ref{fig:fec}.
Chapter~\ref{cha:4} will go into more detail about the readout electronics in the context of our simulation.}

\begin{figure}[h!]
	\centering
		\includegraphics[width=0.75\textwidth]{images/fec.png}
		\caption{Schematics of the readout electronics (From \cite{tdr-016})}
		\label{fig:pad-struct}
\end{figure}

\chapter{Simulations}
\label{cha:4}
\textit{SystemC, Starting design of the simulation, plans for implementation and test runs}

\section{Simulation}
\textit{General simulation theory (Should this be in a previous chapter?)}

\subsection{Theory}
\paragraph{•}
A simulation can be seen as the imitation of a real-world system and its operations over time.
This requires a model representation of the system which is accurate enough to conduct experiments on, which produce real-like results.
The model should include key characteristics, specifications and functions of the selected system, but in a simplified fashion.
A simulation model can take many forms as it can be used in different contexts ranging from physical object such as electrical circuits, bridges, and even entire cities too abstract systems like a mathematical equation or a scientific experiment. %Source

\paragraph{•}
As the model represent the system itself, the simulation represents its operations over a set period of time.
The simulation is normally conducted in a controlled environment that makes it possible to observe, monitor and log results.
To achieve efficient experimenting using a simulation, it should be easy to change its parameters with respect to what is being tested.

\paragraph{•}
There are many benefits of simulating a system instead of creating and test the real thing.
A simulation will in most cases be very time efficient, you can conduct the same kinds of experiments on the system in a much shorter time compared to the real thing.
This means that more information about the systems behavior and limitations in less time, which in turn can result in a better final product.
Creating the real-world system can often be very expensive, which may limit the amount of prototypes or test-products that are possible to create.
Therefore using results of a simulation to fine tune the specifications before starting to produce prototypes will cut unnecessary development costs by a significant margin.

\paragraph{•}
Taking the upgrade of the readout electronics for the \gls{alice} detector as an example to further address this point one can see the usefulness of not having to create multiple custom hardware components, all with different purposed specification.
In regards to the readout electronics, another important point is that the proposed designs might work well from the start, but there is always room for improvement.
Finding out that the design doesn't need as much memory, or less optic fiber cables can impact the overall production costs.
One way to efficiently and accurately simulate hardware components is by creating a virtual computer simulation.

\subsection{Computer Simulation}
\paragraph{•}
Using computers to do simulations is in this day and age become more and more useful because of their incredible computational power, and ability to produce fast results.
This is important as simulations often becomes quite complex, both in regards to computational complexity and hard to work with.
Therefore it can be wise to use existing tools to help make the process easier.
There is an array of different tools that can be used to various kinds of simulations.
They vary from complete frameworks, with graphical user interfaces too tools which helps programmers write there own simulation program.
The later requires of course the most work, but will most often end with the better results as you can custom tailor your simulation on a lower level then with a complete framework.
A programming tool that is made for creating simulations is the SystemC library, which will be discussed in the following section.

\section{SystemC}
\textit{Explain how SystemC works, what benefits and downsides}

\subsection{Background}
\paragraph{•}
\gls{sc} is a system design library based on \gls{cpp}.
It provides an interface for easily create a software models that representing a hardware architecture, and together with standard \gls{cpp} development tools it is possible to quickly build a full scale simulation.
Following the standards of \gls{cpp}, \gls{sc} is built to be easy to understand for both software and hardware developer, resulting in clearer cooperation between them while developing the hardware design.
The \gls{sc} library provides a object-oriented approach to model design, where a single \gls{cpp} class represents a model.
This makes it easy to separate concern between the different models in your simulation.
\paragraph{•}
When simulating a hardware system there is a couple of key points to be aware of, firstly you need to be able to handle hardware timing, clock cycles, and synchronisation.
One of the benefits of \gls{sc} is that it takes care of all of this, again taking advantage of the object-oriented nature of \gls{cpp} to extend its capabilities through \codeword{classes}.
Here is some of the other features \gls{sc} provides, with emphases on the ones needed to understand code snippets shown in this thesis.

\paragraph{•}
\begin{itemize}
\item \textbf{Modules}
	\begin{itemize}
		\item Container \codeword{class} representing a hardware model.
	\end{itemize}
\item \textbf{Processes}
	\begin{itemize}
		\item In short, processes are methods inside a module which describe the module functionality.
	\end{itemize}
\item \textbf{Ports}
	\begin{itemize}
		\item Port represent the input and output points of a module, they can be connected to other modules through Channels.
		Ports can be both one directional or bidirectional.
	\end{itemize}
\item \textbf{Channels}
	\begin{itemize}
		\item Channels are the wires connecting two Ports.
		\gls{sc} comes with three predefined channels: fifo(First-In-First-Out), mutex, and semaphore.
		It is possible to configure custom channels, but in most cases it is not necessary.
	\end{itemize}
\item \textbf{Signals}
	\begin{itemize}
		\item Signals represent data sent between modules via ports.
		They can be arbitrary data types like \codeword{bool} or \codeword{int}, but also user defined types.
	\end{itemize}
\item Rich set of data types
	\begin{itemize}
		\item \gls{sc} supports all data types defined in \gls{cpp} as well as multiple custom types.
	\end{itemize}
\item Clocks
	\begin{itemize}
		\item SystemC comes with the clocks, which can be seen as timekeepers of the system during a simulation.
	\end{itemize}
\end{itemize}

\newpage
\subsection{Small example}

\paragraph{•}
To get a basic understanding of how a \gls{sc} simulation looks like, it is useful to see it in action.
The following Figure~\ref{fig:sc-ex} and Listings~\ref{lst:prod-ex}-\ref{lst:main-ex} make up a very trivial example with only 2 modules; a \codeword{Producer} and a \codeword{Consumer}.
The \codeword{Producer} will increase a counter every clock cycle, and send a \codeword{bool} value based if the count is an even number, and send this value to the \codeword{Consumer}, which registers how many times the \codeword{Producer} counted an even number.
The example uses a \gls{fifo} channel, connected between an output port on the \codeword{Producer}, and an input port on the \codeword{Consumer}.

\begin{figure}[h!]
  \centering
    \includegraphics[width=1.0\textwidth]{images/sc-example.png}
     \caption{Basic SystemC example}
    \label{fig:sc-ex}
\end{figure}

\noindent
\begin{minipage}{\linewidth}
\lstinputlisting[caption=Hello,label=lst:prod-ex]{codelistings/producer.cpp}
\end{minipage}
\begin{minipage}{\linewidth}
\lstinputlisting[caption=Hello,label=lst:cons-ex]{codelistings/consumer.cpp}
\end{minipage}
\begin{minipage}{\linewidth}
\lstinputlisting[caption=Hello,label=lst:main-ex]{codelistings/main.cpp}
\end{minipage}

\paragraph{}
\gls{sc} can be used to create very low level hardware descriptions and models, and can interface directly with hardware description languages like \gls{vhdl} and \gls{verilog}.
This is one way to create a simulation, and the models will be very accurately represented by doing so.
The other way is to have a high level of abstraction, leaving out the unimportant details and focus solely on the expected problem areas.
There are benefits and drawbacks for both ways, but sticking to a high abstraction level can in complex cases make it a lot easier to work with the model design and allows you to focus on the important parts.

\chapter{Problem Description}
\textit{Explain the model, introduce the problem}

\paragraph{}
Føler nesten at det mangler noe her...... (Trenger jeg en introduksjon her?)

\section{Model Design}
\textit{Different design patterns, and plans for the electronic}
The hardware design which is being simulated is already briefly shown in figure~\ref{fig:fec}.
The proposed schematic shown there consists of 12 \gls{fec} cards for every \gls{cru}.
Each \gls{fec} consists of 5 \gls{sampa} and 2 \gls{gbt} \glspl{asic}, with the \gls{cru} being connected to them via 24 optical links.
Out of the 3 main chips, the \gls{sampa} and the \gls{cru} are the most interesting as they are still being developed and testing them can give a lot of valuable feedback.
The \gls{gbt} is a completed component, so even though it is part of readout electronic being simulated, it will only be a very shallow abstraction of it.
This means that it will remain as an empty module who's objective will be to just pass along received data to the correct output links.
One important note about the \gls{gbt} input and output links.
Each \gls{gbt} has 10 input e-links, each with a transfer rate of 320 Mbit/s, giving an effective input speed of 3.2 Gbit/s per \gls{gbt}.
The output is 1 optical fiber link with a speed of 3.2 Gbit/s, giving the \gls{gbt} the same input and output speed.
This is the reason letting data flow directly through the \gls{gbt} in the simulation is possible.
The next sections will go into details about the more important components.

\subsection{SAMPA}
\label{subsec:sampa}
\paragraph{}
The \gls{sampa} \gls{asic} is based on the work from its predecessor, the \gls{altro} chip.
Just like the \gls{altro} chip it will be the first stop for signals being tracking in the \gls{tpc} detector.
The signals will be processed, compressed, digitized, and temporarily stored in the \glspl{sampa} memory before it is passed along.
The \gls{sampa} has 32 integrated channels, which separately and asynchronously process the analog signals coming from the detector.\cite{tdr-016}
Each channel has a readout speed of 10 bit on a 10 MHz clock, which combined results in 3.2 Gbit/s.
The channels also have there own \gls{fifo} buffer memory where signals coming in are stored as they wait to be sent along.
The most efficient size for these buffers are one of the things the simulations will hopefully provide.
The output links for the \gls{sampa} chip consists of 4 e-links connecting them to the \gls{gbt}.
Each e-link has as said in the previous section a speed of 320 Mbit/s, which sums up to 1.28 Gb/s.\cite{tdr-015}
Since each \gls{sampa} and \gls{gbt} has a specific number of output and input links, there is only certain setups which are desirable.
This is why the proposed schematic uses 5 \gls{sampa} and 2 \gls{gbt} chips for each \gls{fec}.
That setup gives exactly 20 output links from the \gls{sampa} chips, and 20 input links on the \gls{gbt} chips.

\paragraph{}
As the \gls{altro}, the \gls{sampa} can be run in triggered readout mode, but in addition can be run continuously.
Being able to read out continuously is a necessary upgrade to handle the increased data load coming from the detector.
During continuous mode the data acquisition is uninterruptable, meaning that there is no pause between reading two consecutive events from the detector.
The difference it makes compared to triggered mode can be seen in figure~\ref{fig:cont-vs-trig}.
Every event, from now on referred to as time frames, is 1024 clock cycles long, and all 32 channels of the \gls{sampa} use the same time frame.
This means that every 1024 clock cycle a 1024 long time window is initiated for all 32 channels, meaning they can readout 10 bit data samples 1024 times during this window.
A synchronization input allows multiple \gls{sampa} \gls{asic}s to align their time frames with respect to each others.\cite{tdr-015}

\begin{figure}[t!]
	\label{fig:cont-vs-trig}
	\centering
		\begin{subfigure}[]{0.9\textwidth}
			\label{fig:cont}
			\includegraphics[width=\textwidth]{images/cont-mode.png}
		\end{subfigure}
		\begin{subfigure}[]{0.9\textwidth}
			\label{fig:trig}
			\includegraphics[width=\textwidth]{images/triggered-mode.png}
		\end{subfigure}
	\caption{Continuous vs Triggered mode}
\end{figure}

\paragraph{}
The \gls{sampa} creates data packets from the data assembled from each time frame.
Consisting of a header of fixed size 50 bit, followed by a list of 10 bit samples, created from a single time frame.
Even though a time frame consists of 1024 clock cycles, in practice a maximum of 1022 samples are received each time.
This is due to 2 * 10 bit words is required to represent cluster size (size of consecutive samples) and a timestamp.
Figure~\ref{fig:packet} shows the structure and format of the packets.

\begin{figure}[h!]
	\centering
		\includegraphics[width=1.0\textwidth]{images/packet.png}
		\caption{Data packet format (From \cite{tdr-015})}
		\label{fig:packet}
\end{figure}

\paragraph{}
The header consists of information regarding the data, such as address for the channel and chip, number of data words in the time frame and packet type.
The packet type is used as a marker to see if anything out of the ordinary has happened to the data.
This can be if there is no samples in the time frame, causing the packet type to just become a channel fill packet.
It can indicate of the stream of data was cut short because the \gls{fifo} buffer was full, causing buffer overflow.
In the case of buffer overflow all data for the particular time frame are discarded and the empty packet is sent with type overflow.
Overflow can cause a lot of data to get discarded if the \gls{sampa} can't empty the buffers fast enough, this can happen if the buffers don't have enough space.
Seeing as the input rate is 3.2 Gbit/s and the readout speed is 1.28 Gbit/s, the \gls{sampa} can receive up to 2.5 more data per second then it can pass along.
This is why the \gls{fifo} buffers are necessary, and finding a size which is sufficient, without going overboard is crucial.

\paragraph{}
There have been done some calculations on how much data will actually be received from the detector at any given time.
It is estimated that on average over all channels for every \gls{sampa} there is around 30\% occupancy.
This means that on a global average there is 30\% data in every given time frame.
Some channels may be full while others are empty, and some may have 40\%, but on average there is 30\%, which means 306 samples out of 1022 for every time frame.
Taking this into account when calculating the input speed of the \gls{sampa} gives 960 Mbit/s which the design should be able to handle without any buffer overflow.
Even though there is an estimated average occupancy there can still be some channels which time frame after time frame gets a lot more then that, so how much can the design handle?
This is some of the question the simulation will give answers to.

\subsection{CRU}
The \gls{cru} serves as an interface between electronics directly on the detector and the online computing systems.
It is based on \gls{fpga} processors, with optical fiber used as input and output. %http://www.altera.com/products/fpga.html
\textit{Hva børr jeg ta med her?}

\section{Signal processing in the SAMPA}
\paragraph{}
The \gls{sampa} chips will receive and process a huge amount of data, both relevant signals and background noise.
In section~\ref{subsec:sampa} we talked about occupancy and amount of samples in each time frame.
The estimated amount of 30\% refers to relevant samples, removing or compressing the background noise.
Seeing as it will always be some interference in the background, there will always come samples with data, and gathering all will be a waist of time and space that could be used on the actual collision data in the detector.
Figure~\ref{fig:signal} shows 2 actual events collected from the 2 different \gls{altro} channels, the events will look similar after the upgrade and we can use this as a starting point.
The x-axis expresses the current time bin within a time frame from 0 to 1021.
Here one can see that every sample in the time frame has some value most with 48-52, as well as certain peaks here and there.
Those peaks are what is interesting, everything else is considered noise and should be removed.
\textit{Hva forusaker støy?}
There are a number of ways to reduce the amount of noise, and/or compress the data to a manageable size.
What has been used with the current setup and is also discussed to use in in the upgraded setup is \gls{zs}.

\begin{figure}[h!]
	\centering
		\includegraphics[width=1.0\textwidth]{images/signal.png}
		\caption{Two signals from a previous experiment}
		\label{fig:signal}
\end{figure}

\subsection{Zero suppression} %With random data, and real data
\paragraph{}
The Oxford Dictionary of Computing (6 ed) defines \gls{zs} in the following way: "The elimination of nonsignificant zeros.
While numerical data is being processed it may be expanded to a uniform number of digits by the addition of nonsignificant zeros to the left of the most significant digit.
For printout or display these nonsignificant zeros may be suppressed."\cite{zerosuppression}.
This is a pretty good summary of what you wish to accomplish with \gls{zs}.
To remove the background noise without discarding any important samples, a baseline for the \gls{zs} must be established.
The problem with this is that the baseline may shift, in the case of our 2 example time frames the first one has a visibly lower baseline by 1 or 2.
In the upgrade plans described in \cite{tdr-015} it specifies how this signal processing will take place.
A short summary is that it is performed in 4 steps:

\begin{itemize}
	\item Initial correction by subtracting the signal using a fixed, previously set signal baseline.
	\item Tail cancellation filter used to cancel slowly varying samples (e.i samples with values close to each other without large spikes).
	\item A second baseline correction which using both a global threshold for each \gls{sampa} and one for specific to each channel.
	\item The actual \gls{zs} which removes everything under a threshold.
\end{itemize}

%
\paragraph{}
\textit{Stemmer dette?}
In some later discussion regarding the upgrade there has been questions if the described method is insufficient.
The theory behind the discussion is that the baseline shift will be to great? to be able to do efficient \gls{zs} without loosing important samples in the process.
This encourage finding another way of processing the signals.
One proposed method is to use Huffman coding on the signal values.

\subsection{Huffman Coding} %Only real data
\paragraph{}
Huffman is a method used to achieve data compression.\cite{huffman}
It works by assigning binary codes to symbols in order to reduce the number of bits used to encode the symbol.
By looking at the frequency of appearance for every symbol used one a frequency table sorted by most frequent.
One thing to note is that since the binary codes is of variable length, they may not all be uniquely decipherable.
For instance, if the codewords looks like the following: \codeword{\{0,01,11,001\}}, the code \codeword{0} is a prefix to \codeword{001}.
This is solved by using the right data structure to store the codes, the one most used is a \textit{full} \gls{bt}.
A \textit{full} \gls{bt} is a tree where every node either has zero or two child nodes.
The symbols are then generated by the path from the root to a leaf node, where left and right indicates 0 or 1.
Figure~\ref{fig:hm-ex} shows an example of a Huffman tree using made up frequencies for the letters A to D.
Here you can see the advantage of sorting by frequency, since the most frequent symbol A only needs one bit to store.
Creating the Huffman tree can be implemented using the following pseudo-code algorithm:

\begin{lstlisting}[caption=Huffman algorithm \cite{algorithms}, label=lst:huffman]
	//Input: An array f[1..n] of frequencies
	//Output: An encoding tree with n leaves
	//let H be a @\gls{pq}@ of integers, ordered by f
	function Huffman(f) {
		for(int i = 1; i <= n; i++){
			H.insert(i);
		}
		for(int k = n+1; k <= 2n - 1; k++){
			i = H.deletemin();
			j = H.deletemin();
			//Create a node numbered k with children i,j
			f[k] = f[i] + f[j];
			H.insert(k);
		}

	}
\end{lstlisting}

\begin{figure}[h!]
	\centering
		\includegraphics[width=1.0\textwidth]{images/huffman.png}
		\caption{Huffman tree with four symbols.}
		\label{fig:hm-ex}
\end{figure}

\paragraph{}
\textit{Need to have Dieter look over this paragraph}
In the context of compressing data coming from the detector there are one particular foreseen complication.
First of, generating the Huffman tree needs values from the detector, so how do one create a tree with high compression factor without knowing this?
One answer to this is to generate a tree using existing data from previous experiments, but update the tree when receiving new data.
This gives us a uncertain compression factor in the beginning, but it will become better over time.
Because of a shifting baseline encoding the signal values directly may lead to a large Huffman tree, and the best tree for one channel may not be the same for another.
It is inefficient to create a separate tree for each channel, as there will be 160 channels for every \gls{fec}.
A possible solution to this is to encode the derivative of each signal in a time frame compared to the previous value.
In other words, for every signal \textit{n} you store the value: \textit{signal(n) - signal(n - 1)}.
Doing so takes away the problem caused by shift in the baseline as it only stores the difference between two signals.
This method requires that the first value of every time frame is stored somewhere(maybe the header of a \gls{sampa} packet) in order to decode it later on.

\section{Designing the simulation model}
With all of the information regarding the different components already specified, creating a simulation model should be more then feasible.
There will be in total 3 main modules part of the simulation: the \gls{sampa}, \gls{gbt} and \gls{cru}.
The tasks, objectives and goals that this all boils down to is summarized in the table below.

\begin{itemize}
	\item \textbf{Tasks}
		\begin{itemize}
			\item Designing a model which is accurate, simple and customizable.
			\item Create a simulation test bench that allows for quick changes in order to run multiple simulations.
			\item Run different stress tests on the system, find out where it breaks and why.
			\item Run focused simulations on the \gls{sampa} channel buffers.
			\item Run simulations which compares \gls{zs} and Huffman encoding.
			\item Gather, and compile the simulation data into a readable and understandable format.
		\end{itemize}
	\item \textbf{Goals}
	\begin{itemize}
		\item Verifying that the design can handle the expected data.
		\item Focus on the
		\item blabla
		\item blabla
	\end{itemize}
\end{itemize}

\paragraph{}
Closing words

\chapter{Solution implementation}
\textit{Code snippets, Incremental implementation stages and the final implementation, (before and after huffman), using real data vs random. Implementing fluxiation into the simulation}
\section{}


\chapter{Evaluation and results}
\textit{Running the tests, results from different tests, Evaluating the final product}

\chapter{Conclusion and Future work}
\textit{Conclude the thesis, talk about the impact it has and its usefulness in future planing of the front end electronics.}

\bibliography{biblio}{}
\bibliographystyle{unsrt}
\end{document}
